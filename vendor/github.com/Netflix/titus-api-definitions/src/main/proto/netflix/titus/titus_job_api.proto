syntax = "proto3";

// Titus job management API specification.
//

package com.netflix.titus;

import "google/protobuf/any.proto";
import "google/protobuf/empty.proto";
import "google/protobuf/wrappers.proto";
import "netflix/titus/titus_base.proto";

option java_multiple_files = true;
option java_package = "com.netflix.titus.grpc.protogen";
option java_outer_classname = "JobProto";

option go_package = "titus";

// ----------------------------------------------------------------------------
// Job specification core data structures

/// An owner of a job.
message Owner {
    /// (Required) An owner's email address.
    string teamEmail = 1;
}

/// Additional information for building a supplementary job identifier, as the 'applicationName' can be shared by
// many jobs running at the same time in Titus. By setting 'JobGroupInfo', a user may create a job id that is guaranteed
// to be unique accross all currently running Titus jobs. The uniquness is checked if any of the attributes
// in this record is a non empty string. The full name is built as: '<application_name>-<stack>-<detail>-<sequence>.
message JobGroupInfo {
    /// (Optional) Any text. It is recommended (but not required), that the value does not include the '-' character.
    string stack = 1;

    /// (Optional) Any text. It is recommended (but not required), that the value does not include the '-' character.
    string detail = 2;

    /// (Optional) Any text. It is recommended (but not required), that the value does not include the '-' character.
    string sequence = 3;
}

/// Task placement constraints. Currently supported constraint types are:
// * zoneBalance - distributes tasks of a job evenly among the availability zones
// * uniqueHost - runs each task of a job on a different agent
// * exclusiveHost - ensures that an agent is exclusively assigned to a given job
message Constraints {
    /// (Optional) A map of constraint name/values. If multiple constraints are given, all must be met (logical 'and').
    map<string, string> constraints = 1;

    /// Not supported yet.
    // (Optional) An expression combining multiple constraints. For example 'zoneBalance AND serverGroup == "mySG"'.
    // Avalilable operators: <, <=, ==, >, >=, in, like, AND, OR
    string expression = 2;
}

/// To reference an image, a user has to provide an image name and a version. A user may specify a version either with
// a tag value (for example 'latest') or a digest. When submitting a job, a user should provide either a tag or a digest value
// only (not both of them).
//
// For example, docker images can be referenced by {name=titus-examples, tag=latest}.
// A user could also choose to provide only the digest without a tag. In this case, the tag value would be empty.
message Image {
    /// (Required) Image name.
    string name = 1;

    /// (Required if digest not set) Image tag.
    string tag = 2;

    /// (Required if tag not set) Image digest.
    string digest = 3;
}

message ContainerResources {
    /// (Required) Number of CPUs to allocate (must be always > 0, but the actual limit is configurable).
    double cpu = 1;

    /// (Optional) Number of GPUs to allocate.
    uint32 gpu = 2;

    /// (Required) Amount of memory to allocate (must be always > 0, but the actual limit is configurable).
    uint32 memoryMB = 3;

    /// (Required) Amount of disk space to allocate (must be always > 0, but the actual limit is configurable).
    uint32 diskMB = 4;

    /// (Required) Amount of network bandwidth to allocate (must be always > 0, but the actual limit is configurable).
    uint32 networkMbps = 5;

    /// (Deprecated) IP always allocated.
    bool allocateIP = 6;

    message EfsMount {
        /// (Required) EFS id
        string efsId = 1;

        /// (Required) EFS mount point
        string mountPoint = 2;

        /// (Required) EFS mount permission mask
        MountPerm mountPerm = 3;

        /// (Optional) EFS relative mount point
        string efsRelativeMountPoint = 4;
    }

    /// (Optional) EFS mounts.
    repeated EfsMount efsMounts = 7;

    /// (Optional) Size of shared memory /dev/shm. If not set, a default value will be provided. A provided value
    // must be less than or equal to amount of memory allocated.
    uint32 shmSizeMB = 8;

    /// (Optional) IP addresses allocated from Titus VPC IP service to be assigned to tasks.
    repeated SignedAddressAllocation signedAddressAllocations = 9;
}

/// Container security profile.
message SecurityProfile {
    /// (Required) Security groups associated with a container. The expected number of security groups is between 1 and 6.
    repeated string securityGroups = 1;

    /// (Required) IAM role.
    string iamRole = 2;

    /// (Optional) Additional security attributes. Key names starting with 'titus.' are reserved by Titus.
    map<string, string> attributes = 3;
}

/// Container descriptor.
message Container {
    /// (Required) Container resources.
    ContainerResources resources = 1;

    /// (Required) Container security profile: IAM role, security groups, container roles.
    SecurityProfile securityProfile = 2;

    /// (Required) Image reference.
    Image image = 3;

    /// (Optional) Arbitrary set of key/value pairs. Key names starting with 'titus.' are reserved by Titus.
    map<string, string> attributes = 4;

    /// (Optional) Override the entry point of the image.
    // If set, the command baked into the image (if any) is always ignored. Interactions between the entry point and
    // command are the same as specified by Docker:
    // https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact
    //
    //  To clear (unset) the entry point of the image, pass a single empty string value: [""]
    repeated string entryPoint = 5;

    /// (Optional) Additional parameters for the entry point defined either here or provided in the container image.
    // To clear (unset) the command of the image, pass a single empty string value: [""]
    repeated string command = 6;

    /// (Optional) A collection of system environment variables passed to the container.
    map<string, string> env = 7;

    /// (Optional) Constraints that Titus will prefer to fulfill but are not required.
    Constraints softConstraints = 8;

    /// (Optional) Constraints that have to be met for a task to be scheduled on an agent.
    Constraints hardConstraints = 9;

    /// (Optional) Experimental features
    google.protobuf.Any experimental = 10;
}

/// This data structure is associated with a service job and specifies the number of tasks to run (desired).
// At any point in time, the condition min <= desired <= max must hold true. The desired state may be changed by a user,
// but also may be changed as a result of an auto-scaling action.
message Capacity {
    /// (Required) Minimum number of tasks to run (min >= 0)
    uint32 min = 1;

    /// (Required) Maximum number of tasks that can be run (max >= desired)
    uint32 max = 2;

    // (Required) Desired number of tasks to run (min <= desired <= max)
    uint32 desired = 3;
}

message JobCapacityWithOptionalAttributes {
    // (Optional) Minimum number of tasks to run (min >= 0)
    google.protobuf.UInt32Value min = 1;

    // (Optional) Maximum number of tasks that can be run (max >= desired)
    google.protobuf.UInt32Value max = 2;

    // (Optional) Desired number of tasks to run (min <= desired <= max)
    google.protobuf.UInt32Value desired = 3;
}

/// Job disruption budget, associated (optionally) with a job.
message JobDisruptionBudget {

    // ----------------------------------------------------
    // Policies

    /// Self managed task relocation policy for users that would like to orchestrate custom termination logic.
    //  If the containers are not terminated within the confgured amount of time, the system default migration
    //  policy is assumed instead.
    message SelfManaged {
        /// Amount of time a container owner has to migrate their containers. A maximum will be enforced by the system.
        uint64 relocationTimeMs = 1;
    }

    /// The minimum required percentage of tasks in a healthy state. Tasks will not be terminated by the eviction service
    //  if this limit would be violated.
    message AvailabilityPercentageLimit {
        double percentageOfHealthyContainers = 1;
    }

    /// The maximum required amount of tasks in an unhealthy state. Tasks will not be terminated by the eviction service
    //  if this limit would be violated.
    message UnhealthyTasksLimit {
        uint32 limitOfUnhealthyContainers = 1;
    }

    /// Maximum number of times a task can be relocated (only batch tasks, which have a maximum execution time).
    message RelocationLimit {
        uint32 limit = 1;
    }

    oneof Policy {
        SelfManaged selfManaged = 1;
        AvailabilityPercentageLimit availabilityPercentageLimit = 2;
        UnhealthyTasksLimit unhealthyTasksLimit = 3;
        RelocationLimit relocationLimit = 4;
    }

    // ----------------------------------------------------
    // Rates

    /// No limits on how many containers in a job may be relocated, provided the other disruption budget constraints are not violated.
    message RateUnlimited {
    }

    /// Allow up to the given percentage of tasks to be relocated within an hour.
    message RatePercentagePerHour {
        double maxPercentageOfContainersRelocatedInHour = 1;
    }

    /// Allow up to the given amount of relocations per the time interval.
    message RatePerInterval {
        uint64 intervalMs = 1;
        uint32 limitPerInterval = 2;
    }

    /// Percentage of containers that can be relocated within a time interval. The number of containers is determined
    //  during each evaluation, and the number is based on the current desired job size. If the job size changes, the percentage of containers
    //  changes accordingly. For example, setting / interval to 60000 (1 minute) and ratePercentagePerInterval to 5 (5%)
    //  would allow only for up to 5% of all containers to be relocated every minute, given the other criteria are met.
    //  For a job with a desired size of 100, 5 container relocations per minute would be allowed. If the desired job size changes
    //  to 200, the relocation rate increases to 10 containers per minute.
    message RatePercentagePerInterval {
        uint64 intervalMs = 1;
        double percentageLimitPerInterval = 2;
    }

    oneof Rate {
        RateUnlimited rateUnlimited = 5;
        RatePercentagePerHour ratePercentagePerHour = 6;
        RatePerInterval ratePerInterval = 9;
        RatePercentagePerInterval ratePercentagePerInterval = 10;
    }

    /// (Optional) Time window to which relocation process is restricted.
    repeated TimeWindow timeWindows = 7;

    /// (Optional) Container health providers to use when relocating a container.
    repeated ContainerHealthProvider containerHealthProviders = 8;
}

/// Batch job specification.
message BatchJobSpec {
    /// (Required) Number of tasks to run (>= 0).
    uint32 size = 1;

    /// (Required) Maximum amount of time in seconds that the job's task is allowed to run. The timer is started once the task
    // transitions to the 'RUNNING' state. If a task terminates with an error and is restarted, the timer starts again from 0.
    uint64 runtimeLimitSec = 2;

    /// (Required) Task rescheduling policy in case of failure.
    RetryPolicy retryPolicy = 3;

    /// true when the task should be restarted after being terminated due to runtime limit.
    bool retryOnRuntimeLimit = 4;
}

/// Migration polices.
message MigrationPolicy {
    /// The system default migration policy.
    message SystemDefault {
    }

    /// The self managed policy where the owner needs to migrate the tasks.
    message SelfManaged {
    }

    /// (Required) Migration policy.
    oneof Policy {
        SystemDefault systemDefault = 1;
        SelfManaged selfManaged = 2;
    }
}

/// Migration details
message MigrationDetails {
    /// true when the the task needs to be migrated to another agent.
    bool needsMigration = 1;

    /// The deadline time that the owner must migrate their task by or the system will automatically do it.
    /// This value is irrelevant if 'needsMigration' is set to false and will default to the value '0'.
    uint64 deadline = 2;

    /// Time at which the migration decision was made.
    /// This value is irrelevant if 'needsMigration' is set to false and will default to the value '0'.
    uint64 started = 3;
}

/// Service job specification.
message ServiceJobSpec {

    /// (Required) Number of tasks to run. If a scaling policy is defined, the number of tasks created will be always
    // within min/max range.
    Capacity capacity = 1;

    /// (Optional) Job enable/disable status. If a job is disabled, auto-scaling policies are not applied.
    bool enabled = 2;

    /// (Required) Task rescheduling policy in case of failure.
    RetryPolicy retryPolicy = 3;

    /// (Optional) Migration policy for how the tasks will be migrated during an infrastructure change.
    // If not set, defaults to SystemDefault.
    MigrationPolicy migrationPolicy = 4;

    /// Configuration of service job processes
    message ServiceJobProcesses {
        /// Prevents increasing the Job's desired capacity. Existing tasks that exit such as the process exiting will still be replaced.
        bool disableIncreaseDesired = 1;

        /// Prevents decreasing the Job's desired capacity. Existing tasks that exit such as the process exiting will still be replaced.
        bool disableDecreaseDesired = 2;
    }

    /// (Optional) Job scaling activity configurations.
    ServiceJobProcesses serviceJobProcesses = 5;
}

/// Job descriptor contains the full job specification (batch or service) that is used to run a job.
message JobDescriptor {

    /// (Optional) Owner of a job (see Owner entity description for more information).
    Owner owner = 1;

    /// (Required) Free form name.
    string applicationName = 3;

    /// (Optional) Capacity group associated with a job. If not set, defaults to 'DEFAULT'.
    string capacityGroup = 4;

    /// (Optional) Mostly relevant for service jobs, but applicable to batch jobs as well, allows a user to specify
    // own unique identifier for a job (see JobGroupInfo for more information).
    JobGroupInfo jobGroupInfo = 5;

    /// (Optional) Arbitrary set of key/value pairs. Names starting with 'titus' (case does not matter) are reserved for an internal use.
    map<string, string> attributes = 6;

    /// (Required) Container to be executed for a job.
    Container container = 7;

    /// (Required) Additional information required for job execution, specific to job type.
    oneof JobSpec {
        /// Batch job specific descriptor.
        BatchJobSpec batch = 8;

        /// Service job specific descriptor.
        ServiceJobSpec service = 9;
    };

    /// (Optional) Job disruption budget. If not defined, a job type specific (batch or service) default is set.
    JobDisruptionBudget disruptionBudget = 10;
}

/// Composite data structure holding both job state information and the reason of the transition to this state.
message JobStatus {

    /// State information associated with a job.
    enum JobState {
        /// A job is persisted in Titus and is ready to be scheduled.
        Accepted = 0;

        /// A job still has running tasks that were requested to be terminated. No more tasks for this job are deployed.
        //  Job policy update operations are not allowed.
        KillInitiated = 1;

        /// A job has no running tasks, and new tasks cannot be created. Job policy update operations are not allowed.
        Finished = 2;
    }

    /// (Required) Job state
    JobState state = 1;

    /// (Optional) An identifier of an event that caused a transition to this state. Each job manager can introduce its own
    //  set of reason codes. As of now, there are no common reason codes defined for jobs.
    string reasonCode = 2;

    /// (Optional) Textual description accompanying the 'reasonCode'.
    string reasonMessage = 3;

    /// Time when a transition to a state happened.
    uint64 timestamp = 4;
}

message TaskStatus {

    /// State information associated with a task.
    enum TaskState {

        /// A task was passed to the scheduler but has no resources allocated yet.
        Accepted = 0;

        /// A task had resources allocated and was passed to Mesos.
        Launched = 1;

        /// An executor provisioned resources for a task.
        StartInitiated = 2;

        /// The container was started.
        Started = 3;

        /// A user requested the task to be terminated. An executor is stopping the task and releasing its allocated resources.
        KillInitiated = 4;

        /// No connectivity between Mesos and an agent running a task. The task's state cannot be determined until the connection
        //  is established again.
        Disconnected = 5;

        /// A task completed or was forced by a user to be terminated. All resources previously assigned to this task are released.
        Finished = 6;
    }

    /// (Required) Task state
    TaskState state = 1;

    /// (Optional) An identifier of an event that caused a transition to this state. Each job manager can introduce its own
    //  set of reason codes. Below are the predefined (common) set of reason codes associated with task state 'Finished':
    //  * 'normal'               - task completed with the exit code 0
    //  * 'failed'               - task completed with a non zero error code
    //  * 'killed'               - task was explicitly terminated by a user
    //  * 'scaledDown'           - task was terminated as a result of job scaling down
    //  * 'stuckInState'         - task was terminated, as it did not progress to the next state in the expected amount of time
    //  * 'runtimeLimitExceeded' - task was terminated, as its runtime limit was exceeded
    //  * 'lost'                 - task was lost, and its final status is unknown
    //  * 'invalidRequest'       - invalid container definition (security group, image name, etc)
    //  * 'crashed'              - container crashed due to some internal system error
    //  * 'transientSystemError' - transient error, not agent specific (for example AWS rate limiting)
    //  * 'localSystemError'     - an error scoped to an agent instance on which a container was run.
    //                             The agent should be quarantined or terminated.
    //  * 'unknownSystemError'   - unknown error which cannot be classified either as local/non-local or transient.
    //                             If there are multiple occurences of this error, the agent should be quarantined or terminated.
    string reasonCode = 2;

    /// (Optional) Textual description accompanying the 'reasonCode'.
    string reasonMessage = 3;

    /// Time when a transition to a state occurred.
    uint64 timestamp = 4;
}

/// Task log locations
message LogLocation {

    /// URL pointing to a UI based log viewer.
    message UI {
        /// (Required) UI URL.
        string url = 1;
    }

    /// URL address to a container log service. When a container is running, its stdout/stderr or any other file in the
    //  '/logs' folder can be acccessed via this endpoint. The endpoint becomes unavailable when the container terminates.
    //
    //  A user should provide the 'f' query parameter to specify a file to download. If the 'f' query parameter is net set,
    //  it defaults to 'stdout'. The file path must be relative to the '/logs' folder.
    message LiveStream {
        /// (Required) Live log URL.
        string url = 1;
    }

    /// Location of S3 folder containing container's log files.
    message S3 {
        /// (Required) AWS account name.
        string accountName = 1;

        /// (Required) AWS account id.
        string accountId = 2;

        /// (Required) AWS region.
        string region = 3;

        /// (Required) S3 bucket.
        string bucket = 4;

        /// (Required) The key prefix in the S3 bucket. The assumption is that the consumer finds all objects based on this key prefix.
        string key = 5;
    }

    /// (Required) Log access via UI.
    UI ui = 1;

    /// (Optional) Live log access. Provided only for running tasks.
    LiveStream liveStream = 2;

    /// (Required) S3 log location.
    S3 s3 = 3;
}

/// Task is an entity representing a running container.
message Task {
    /// (Required) The Id of the task.
    string id = 1;

    /// (Required) Id of a job that owns this task.
    string jobId = 2;

    /// (Required) Includes:
    // * agent execution environment: 'agent.region', 'agent.zone', 'agent.host', 'agent.instanceId'
    // * job type specific information: 'task.index', 'task.resubmitOf' (id of task which this task is replacing), 'task.originalId' (id of task which this task is a replacement)
    map<string, string> taskContext = 3;

    /// (Required) Last known state of this task.
    TaskStatus status = 4;

    /// (Required) State transition history.
    repeated TaskStatus statusHistory = 5;

    /// (Required) Container logs.
    LogLocation logLocation = 6;

    /// (Required) Migration details.
    MigrationDetails migrationDetails = 7;

    /// (Optional) User defined key/value pairs.
    map<string, string> attributes = 8;
}

/// Job entity is returned by query operations only.
message Job {

    /// (Required) The unique id (UUID).
    string id = 1;

    /// (Required) Job descriptor.
    JobDescriptor jobDescriptor = 2;

    /// (Required) Last known job state.
    JobStatus status = 3;

    /// (Required) State transition history.
    repeated JobStatus statusHistory = 4;
}

// ----------------------------------------------------------------------------
// Change notification model

/// Job event stream consists of two phases. In the first phase, a snapshot of the current state (a job and its tasks) is
//  streamed, and it is followed by the SnapshotEnd notification marker. In the second phase, job/task state updates are
//  sent. When a job is terminated, the stream completes.
message JobChangeNotification {

    /// Emitted when a new job is created or when any of the job's attributes change.
    message JobUpdate {
        Job job = 1;
    }

    /// Emitted when a task is created or its state has changed.
    message TaskUpdate {
        Task task = 1;
        /// movedFromAnotherJob will be true on the first event for the target Job after a task is moved between jobs.
        //  task.jobId will be the destination job, and it will include a 'task.movedFromJob' entry in its taskContext
        //  map with the source jobId.
        bool movedFromAnotherJob = 2;
    }

    /// A notification marker that indicates that all known jobs were streamed to the client.
    message SnapshotEnd {
    }

    oneof Notification {
        JobUpdate jobUpdate = 1;
        TaskUpdate taskUpdate = 2;
        SnapshotEnd snapshotEnd = 3;
    }
}

// ----------------------------------------------------------------------------
// Data model used in the durable storage.

message JobDataRecord {

    DataRecordMetadata metadata = 1;

    Job job = 2;
}

message TaskDataRecord {

    DataRecordMetadata metadata = 1;

    Job job = 2;

    Task task = 3;
}

// ----------------------------------------------------------------------------
// GRPC services
//
// The data structures below are wrapper messages that are not part of the
// core data model.

message JobId {
    string id = 1;
}

message JobIds {
    repeated string id = 1;
}

// Job query request. The query result is limited to the active data set. Finished jobs/tasks are not evaluated
// when the query is executed.
message JobQuery {
    /// (Required) Requested page number/size.
    Page page = 1;

    // ---------------------------------------------------
    // Filtering criteria

    /// (Optional) Collection of fields and their values for a filter.
    // Available query criteria:
    // jobIds - list of comma separated job ids
    // taskIds - list of comma separated task ids
    // owner - job owner
    // applicationName - job application name
    // imageName - image name
    // imageTag - image tag
    // capacityGroup - job assigned capacity group
    // jobGroupStack - job group stack
    // jobGroupDetail - job group details
    // jobGroupSequence - job group sequence
    // jobType - job type (batch or service)
    // attributes - comma separated job attribute key/value pairs (for example "key1,key2:value2;k3:value3")
    // attributes.op - logical 'and' or 'or' operators, which should be applied to multiple attributes specified in the query
    // jobState - job state (one)
    // taskStates - task states (multiple, comma separated). Empty value is the same as no value set.
    // taskStateReasons - reasons associated with task states (multiple, comma separated)
    // needsMigration - if set to true, return only jobs with tasks that require migration
    map<string, string> filteringCriteria = 2;

    // ---------------------------------------------------
    // Output

    /// (Optional) If set, only field values explicitly specified in this parameter will be returned
    // This does not include certain attributes like 'jobId', 'appName' which are always returned.
    // If the nested field value is provided, only the explicitly listed nested fields will be returned.
    // For example: tasks.taskId rule will result in including just this value when encoding Task entity.
    repeated string fields = 5;
}

message JobQueryResult {
    repeated Job items = 1;
    Pagination pagination = 2;
}

// The filtering criteria is applied to both Job and Task events. If a criteria applies to task fields, the stream will
// include both task events matching it, and events for jobs with tasks that match it. The opposite is also true, e.g.:
// a criteria on applicationName (a job field) will include both job events matching it, and events for tasks belonging
// to a job that matches it.
message ObserveJobsQuery {
    // ---------------------------------------------------
    // Filtering criteria

    /// (Optional) Collection of fields and their values for a filter.
    // Available query criteria:
    // jobIds - list of comma separated job ids
    // taskIds - list of comma separated task ids
    // owner - job owner
    // applicationName - job application name
    // imageName - image name
    // imageTag - image tag
    // capacityGroup - job assigned capacity group
    // jobGroupStack - job group stack
    // jobGroupDetail - job group details
    // jobGroupSequence - job group sequence
    // jobType - job type (batch or service)
    // attributes - comma separated job attribute key/value pairs. The same key may occur multiple times, with different
    //              values (any value matches the filter). A value may be omitted, in which case if the key
    //              occurs only once, only presence of the key is checked, without value comparison (otherwise the value
    //              is an empty string). Example filters:
    //              * 'key1' - matches, if the key is present
    //              * 'key2:value2' - matches if the attributes contain key 'key2' with value 'value2'
    //              * 'key3,key3:value3a,key3:value3b' - matches if the attributes contain key 'key3' with value '' or 'value3a' or 'value3b'
    //              All the above can be passed together as 'key1,key2:value2,key3,key3:value3a,key3:value3b'
    // attributes.op - logical 'and' or 'or' operators, which should be applied to multiple attributes specified in the query
    // jobState - job state (one)
    // taskStates - task states (multiple, comma separated). Empty value is the same as no value set.
    // taskStateReasons - reasons associated with task states (multiple, comma separated)
    // needsMigration - if set to true, return only jobs with tasks that require migration
    map<string, string> filteringCriteria = 1;
}

message JobCapacityUpdate {
    string jobId = 1;
    Capacity Capacity = 2;
}

message JobCapacityUpdateWithOptionalAttributes {
    string jobId = 1;
    JobCapacityWithOptionalAttributes jobCapacityWithOptionalAttributes = 2;
}

message JobStatusUpdate {
    string id = 1;
    bool enableStatus = 2;
}

message JobProcessesUpdate {
    string jobId = 1;
    ServiceJobSpec.ServiceJobProcesses serviceJobProcesses = 2;
}

message JobDisruptionBudgetUpdate {
    string jobId = 1;
    JobDisruptionBudget disruptionBudget = 2;
}

message JobAttributesUpdate {
    string jobId = 1;
    map<string, string> attributes = 2;
}

message JobAttributesDeleteRequest {
    string jobId = 1;
    repeated string keys = 2;
}

message TaskId {
    string id = 1;
}

message TaskIds {
    repeated string id = 1;
}

// Task query request. The query result is limited to the active data set. Finished jobs/tasks are not evaluated
// when the query is executed.
message TaskQuery {
    /// (Required) Requested page number/size.
    Page page = 1;

    /// (Optional) Collection of fields and their values for a filter.
    // Available query criteria:
    // jobIds - list of comma separated job ids
    // taskIds - list of comma separated task ids
    // owner - job owner
    // applicationName - job application name
    // imageName - image name
    // imageTag - image tag
    // capacityGroup - job assigned capacity group
    // jobGroupStack - job group stack
    // jobGroupDetail - job group details
    // jobGroupSequence - job group sequence
    // jobType - job type (batch or service)
    // attributes - comma separated job attribute key/value pairs. The same key may occur multiple times, with different
    //              values (any value matches the filter). A value may be omitted, in which case if the key
    //              occurs only once, only presence of the key is checked, without value comparison (otherwise the value
    //              is an empty string). Example filters:
    //              * 'key1' - matches, if the key is present
    //              * 'key2:value2' - matches if the attributes contain key 'key2' with value 'value2'
    //              * 'key3,key3:value3a,key3:value3b' - matches if the attributes contain key 'key3' with value '' or 'value3a' or 'value3b'
    //              All the above can be passed together as 'key1,key2:value2,key3,key3:value3a,key3:value3b'
    // attributes.op - logical 'and' or 'or' operators, which should be applied to multiple attributes specified in the query
    // jobState - job state (one)
    // taskStates - task states (multiple, comma separated). Empty value is the same as no value set.
    // taskStateReasons - reasons associated with task states (multiple, comma separated)
    // needsMigration - if set to true, return only tasks that require migration
    // skipSystemFailures - a filter for finished tasks only (does not affect non-finished tasks). If set to true,
    //                      a finished task that failed due to a system error is filtered out. System error codes
    //                      are specified in the TaskStatus type definition. These are container failures due to Titus
    //                      internal issues.
    map<string, string> filteringCriteria = 2;

    /// (Optional) If set, only field values explicitly given in this parameter will be returned
    repeated string fields = 3;
}

message TaskQueryResult {
    repeated Task items = 1;
    Pagination pagination = 2;
}

message TaskKillRequest {
    /// (Required) Task to kill.
    string taskId = 1;

    /// (Optional) Should job size be reduced
    bool shrink = 2;

    // (Optional) If set to true, and this is a terminate and shrink request ('shrink' set to true), reject
    // the kill request if it would cause the job size go below the current minimum size. Otherwise, the job
    // size minimum size is decremented by 1.
    bool preventMinSizeUpdate = 3;
}

message TaskAttributesUpdate {
    string taskId = 1;
    map<string, string> attributes = 2;
}

message TaskAttributesDeleteRequest {
    string taskId = 1;
    repeated string keys = 2;
}

message TaskMoveRequest {
    /// (Required) Source Job(Service) distinct from target job which is the source of the task.
    string sourceJobId = 1;

    /// (Required) Target Job(Service) distinct from source job which is the recipient of the task.
    string targetJobId = 2;

    /// (Required) Task to move. Task must be in started state.
    string taskId = 3;
}

service JobManagementService {

    // ------------------------------------------------------------
    // Job operations

    /// Create a new job
    rpc CreateJob (JobDescriptor) returns (JobId) {
    }

    /// Modify the number of instances for a service job.
    rpc UpdateJobCapacity (JobCapacityUpdate) returns (google.protobuf.Empty) {
    }

    /// Modify job capacity for a service job. It allows you to specify only values (min / max / desired) that need to be updated.
    rpc UpdateJobCapacityWithOptionalAttributes (JobCapacityUpdateWithOptionalAttributes) returns (google.protobuf.Empty) {
    }

    /// Mark a job as enabled or disabled. Disabled jobs are not auto-scaled.
    rpc UpdateJobStatus (JobStatusUpdate) returns (google.protobuf.Empty) {
    }

    /// Update service job processes such as disable increase/decrease instance count
    rpc UpdateJobProcesses (JobProcessesUpdate) returns (google.protobuf.Empty) {
    }

    /// Update a job disruption budget.
    rpc UpdateJobDisruptionBudget (JobDisruptionBudgetUpdate) returns (google.protobuf.Empty) {
    }

    // Return a collection of jobs matching the given criteria. The query result is limited to the active data set.
    // Finished jobs/tasks are not evaluated when the query is executed.
    rpc FindJobs (JobQuery) returns (JobQueryResult) {
    }

    /// Return a job with given id.
    rpc FindJob (JobId) returns (Job) {
    }

    /// On subscription, sends complete job (definition and active tasks). Next, send distinct job definition
    // or task state chage notifications. The stream is closed by the server only when the job is finished, which
    // happens after the 'JobFinished' notification is delivered.
    rpc ObserveJob (JobId) returns (stream JobChangeNotification) {
    }

    /// Equivalent to ObserveJob, applied to all active jobs. This stream never completes.
    rpc ObserveJobs (ObserveJobsQuery) returns (stream JobChangeNotification) {
    }

    /// Terminate all running tasks of a job, and than terminate the job.
    rpc KillJob (JobId) returns (google.protobuf.Empty) {
    }

    /// Update the attributes of a job. This will either create new attributes or replace existing ones with the same key.
    rpc UpdateJobAttributes (JobAttributesUpdate) returns (google.protobuf.Empty) {
    }

    /// Delete the attributes of a job.
    rpc DeleteJobAttributes (JobAttributesDeleteRequest) returns (google.protobuf.Empty) {
    }

    // ------------------------------------------------------------
    // Task operations

    /// Get a task with the specified id.
    rpc FindTask (TaskId) returns (Task) {
    }

    // Return a collection of tasks specified in the 'TaskQuery' request matching the given criteria. The query result is
    // limited to the active data set. Finished jobs/tasks are not evaluated when the query is executed.
    rpc FindTasks (TaskQuery) returns (TaskQueryResult) {
    }

    /// Terminate a task with the given id. Depending on job type, the task might be immediately restarted/replaced with a new one.
    rpc KillTask (TaskKillRequest) returns (google.protobuf.Empty) {
    }

    /// Update the attributes of a task. This will either create new attributes or replace existing ones with the same key.
    rpc UpdateTaskAttributes (TaskAttributesUpdate) returns (google.protobuf.Empty) {
    }

    /// Delete the attributes of a task.
    rpc DeleteTaskAttributes (TaskAttributesDeleteRequest) returns (google.protobuf.Empty) {
    }

    /// Move a task from one service job to another. Source and destination jobs must be service jobs, and compatible.
    // Jobs are compatible when their JobDescriptors are identical, ignoring the following values:
    //
    // * owner
    // * applicationName
    // * jobGroupInfo (stack, details, sequence)
    // * disruptionBudget
    // * Any attributes not prefixed with `titus.` or `titusParameter.`
    // * Any container.attributes not prefixed with `titus.` or `titusParameter.`
    // * All information specific to service jobs (JobSpec): Capacity, RetryPolicy, MigrationPolicy, etc
    rpc MoveTask (TaskMoveRequest) returns (google.protobuf.Empty) {
    }
}
